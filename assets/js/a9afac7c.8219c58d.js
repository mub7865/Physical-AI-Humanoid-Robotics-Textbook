"use strict";(globalThis.webpackChunkbook=globalThis.webpackChunkbook||[]).push([[7178],{6102:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"chapter-4-isaac/weekly-breakdown-weeks-8-10","title":"Weekly Breakdown: Weeks 8-10 \u2013 The AI-Robot Brain \ud83d\uddd3\ufe0f","description":"Overview","source":"@site/docs/chapter-4-isaac/weekly-breakdown-weeks-8-10.md","sourceDirName":"chapter-4-isaac","slug":"/chapter-4-isaac/weekly-breakdown-weeks-8-10","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/chapter-4-isaac/weekly-breakdown-weeks-8-10","draft":false,"unlisted":false,"editUrl":"https://github.com/mub7865/Physical-AI-Humanoid-Robotics-Textbook/tree/main/book/docs/chapter-4-isaac/weekly-breakdown-weeks-8-10.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"The AI-Robot Brain: Inside NVIDIA Isaac\u2122 \ud83e\udd16\ud83e\udde0","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/chapter-4-isaac/the-ai-robot-brain"},"next":{"title":"Chapter 5: Humanoid VLA Development","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/docs/category/chapter-5-humanoid-vla-development"}}');var a=t(4848),s=t(8453);const o={},r="Weekly Breakdown: Weeks 8-10 \u2013 The AI-Robot Brain \ud83d\uddd3\ufe0f",l={},c=[{value:"Overview",id:"overview",level:2},{value:"\ud83d\udcc5 Week 8: Isaac Sim &amp; Synthetic Data Generation",id:"-week-8-isaac-sim--synthetic-data-generation",level:2},{value:"\ud83d\udcc5 Week 9: Perception with Isaac ROS",id:"-week-9-perception-with-isaac-ros",level:2},{value:"\ud83d\udcc5 Week 10: Advanced Control &amp; Sim-to-Real",id:"-week-10-advanced-control--sim-to-real",level:2},{value:"\ud83c\udfc6 Assessment: Isaac-Based Perception Pipeline",id:"-assessment-isaac-based-perception-pipeline",level:2},{value:"Ready to Upgrade the Brain?",id:"ready-to-upgrade-the-brain",level:3}];function d(e){const n={em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"weekly-breakdown-weeks-8-10--the-ai-robot-brain-\ufe0f",children:"Weekly Breakdown: Weeks 8-10 \u2013 The AI-Robot Brain \ud83d\uddd3\ufe0f"})}),"\n",(0,a.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsxs)(n.p,{children:["Welcome to the cutting edge. Over the next three weeks, we will leave traditional robotics behind and enter the world of ",(0,a.jsx)(n.strong,{children:"AI-Driven Robotics"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["You will learn to use the ",(0,a.jsx)(n.strong,{children:"NVIDIA Isaac Platform"}),"\u2014the same tools used by industry giants like Tesla and Amazon Robotics. We will move from manually programming robot movements to training AI brains that ",(0,a.jsx)(n.em,{children:"learn"})," to move."]}),"\n",(0,a.jsx)(n.p,{children:'By the end of Week 10, you will have a robot that can "see" using computer vision and "think" using reinforcement learning.'}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"-week-8-isaac-sim--synthetic-data-generation",children:"\ud83d\udcc5 Week 8: Isaac Sim & Synthetic Data Generation"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Goal:"})," Build the Photorealistic Training Ground."]}),"\n",(0,a.jsx)(n.p,{children:"In this week, we focus on setting up the environment where our AI will learn."}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Installation & Setup:"})," Installing NVIDIA Omniverse and the Isaac Sim application."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"USD Assets:"})," Understanding the Universal Scene Description format. We will import high-fidelity robot models and environments (e.g., a warehouse or a hospital)."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Synthetic Data Generation (SDG):"})," This is the magic.","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:'We will set up a "Replicator" script.'}),"\n",(0,a.jsx)(n.li,{children:"We will generate 10,000 labeled images of a target object (e.g., a package)."}),"\n",(0,a.jsxs)(n.li,{children:["We will apply ",(0,a.jsx)(n.strong,{children:"Domain Randomization"})," (changing lights, textures, camera angles) to make the dataset robust."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Key Deliverable:"})," A dataset of 1,000+ perfectly labeled images generated automatically from Isaac Sim."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"-week-9-perception-with-isaac-ros",children:"\ud83d\udcc5 Week 9: Perception with Isaac ROS"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Goal:"})," Give the Robot Eyes (VSLAM & Object Detection)."]}),"\n",(0,a.jsxs)(n.p,{children:["Now that we have data, let's give the robot the ability to perceive the world. We will use ",(0,a.jsx)(n.strong,{children:"Isaac ROS GEMs"}),"\u2014hardware-accelerated packages running on the GPU."]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Isaac ROS VSLAM:"})," We will replace the expensive LiDAR with a stereo camera. You will see the robot build a map of the room using only visual landmarks."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Object Detection (YOLO/DOPE):"}),' We will deploy a neural network that identifies objects (e.g., "Person", "Chair", "Forklift") in real-time.']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Hardware Acceleration:"})," Understanding how to use the Jetson Orin's GPU to process images at 60 FPS (which would choke a standard CPU)."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Key Deliverable:"})," A ROS 2 node that outputs the location of specific objects in the room using camera data."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"-week-10-advanced-control--sim-to-real",children:"\ud83d\udcc5 Week 10: Advanced Control & Sim-to-Real"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Goal:"})," Reinforcement Learning and Navigation."]}),"\n",(0,a.jsxs)(n.p,{children:["This is the final frontier. We stop telling the robot ",(0,a.jsx)(n.em,{children:"how"})," to move and start telling it ",(0,a.jsx)(n.em,{children:"what"})," to achieve."]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Nav2 Integration:"}),' Using the Navigation Stack 2 with Isaac Sim. We will tell the robot "Go to the Kitchen," and it will plan a path around dynamic obstacles (like people).']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Reinforcement Learning (RL):"})," An introduction to ",(0,a.jsx)(n.strong,{children:"Isaac Gym"}),". We will train a simple robot to balance itself or walk by rewarding it for success and punishing it for failure."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Sim-to-Real Transfer:"}),' The moment of truth. We will take the model trained in Week 8/9 and deploy it to the physical Jetson Edge Kit. We will discuss techniques to bridge the "Reality Gap."']}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Key Deliverable:"})," A robot navigating a complex environment autonomously using Nav2 and VSLAM."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"-assessment-isaac-based-perception-pipeline",children:"\ud83c\udfc6 Assessment: Isaac-Based Perception Pipeline"}),"\n",(0,a.jsx)(n.p,{children:"At the end of Module 3, you will be assessed on your ability to build a full perception system."}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"The Project:"}),"\r\nYou must submit a video demo and code for a ",(0,a.jsx)(n.strong,{children:'"Search and Rescue"'})," scenario in Isaac Sim:"]}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Map:"})," The robot must map an unknown environment using VSLAM."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Detect:"}),' The robot must identify a "Target" (e.g., a red box) using an Object Detection model.']}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Navigate:"})," Upon detecting the target, the robot must autonomously navigate to it and stop within 1 meter."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"ready-to-upgrade-the-brain",children:"Ready to Upgrade the Brain?"}),"\n",(0,a.jsxs)(n.p,{children:["Prepare your GPUs. We are diving into ",(0,a.jsx)(n.strong,{children:"Week 8: Isaac Sim"}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>r});var i=t(6540);const a={},s=i.createContext(a);function o(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);